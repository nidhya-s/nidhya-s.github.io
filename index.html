<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Nidhya Shivakumar</title>

    <meta name="author" content="Nidhya Shivakumar">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" type="image/png" href="images/seal.png">
    <link rel="shortcut icon" href="images/seal.png" type="image/png">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
</head>

<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Nidhya Shivakumar
                </p>
                <p>
		        I'm a junior at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a> studying Electrical Engineering and Computer Science. I work in <a href="https://goldberg.berkeley.edu/">Professor Ken Goldberg's</a> <a href="https://autolab.berkeley.edu/">AUTOLab</a> on several projects related to robotics and computer vision.
            I previously worked at Google for two summers in 2024 and 2025 on the Shopping Ads Infrastructure team and Youtube's Trust & Safety team, respectively.
                </p>
                <p style="text-align:center">
                  <a href="mailto:nidhya@berkeley.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://github.com/nidhya-s">Github</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=pMQw-ncAAAAJ&hl=en&authuser=1">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="data/Shivakumar, Nidhya Resume.pdf">Résumé</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/nidhya-shivakumar/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/headshot.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/headshot.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <!-- <p>
                  I'm interested in computer vision, deep learning, and image processing.
                </p> -->
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr onmouseout="nexf_stop()" onmouseover="nexf_start()">
      <td style="padding:16px;width:20%;vertical-align:top">
        <div class="one">
          <div class="two" id='nexf_image'>
					  <img src='images/handloom.png' width=100%>
                                        </div>
          <img src='images/handloom.png' width=100%>
                                        </div>
        <script type="text/javascript">
          function nexf_start() {
            document.getElementById('nexf_image').style.opacity = "1";
          }

          function nexf_stop() {
            document.getElementById('nexf_image').style.opacity = "0";
          }
          nexf_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:top">
        <a href="https://deformable-workshop.github.io/icra2025/spotlight/02_07_16_Shivakumar_HANDLOOM.pdf">
          <span class="papertitle">HANDLOOM 3.0: Interactive Bi-Directional Cable Tracing Amid Clutter</span>
        </a>
        <br>
        <a href="https://uynitsuj.github.io/about/">Justin Yu</a>*,
        <strong>Nidhya Shivakumar</strong>*,
        <a href="https://www.linkedin.com/in/veenasumedh/">Veena Sumedh</a>*,
        <a href="https://www.linkedin.com/in/itsjoshzhang/">Josh Zhang</a>,
        <a href="https://www.linkedin.com/in/ethan-ransing/">Ethan Ransing</a>,
        <a href="https://osheraz.github.io/">Osher Azulay</a>,
        <a href="https://goldberg.berkeley.edu/">Ken Goldberg</a>
        <br>
        <em>ICRA 2025 Deformable Objects Workshop</em>, 2025 &nbsp <font color="#666">*Equal contribution</font>
        <br>
        <a href="https://deformable-workshop.github.io/icra2025/spotlight/02_07_16_Shivakumar_HANDLOOM.pdf">PDF</a>
        <p></p>
        <p>
		Interactive bi-directional cable tracing system for robotic manipulation in cluttered environments.
        </p>
      </td>
    </tr>
	
    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()">
      <td style="padding:16px;width:20%;vertical-align:top">
        <div class="one">
          <div class="two" id='bolt3d_image'>
					  <img src='images/lilac.png' width=100%>
                                        </div>
          <img src='images/lilac.png' width=100%>
                                        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:top">
        <a href="https://arxiv.org/abs/2301.02555">
          <span class="papertitle">"No, to the Right" -- Online Language Corrections for Robotic Manipulation via Shared Autonomy</span>
        </a>
        <br>
        <a href="https://yuchencui.cc/">Yuchen Cui</a>,
        <a href="https://www.siddkaramcheti.com/">Siddharth Karamcheti</a>,
        <a href="https://scholar.google.com/citations?user=JmmDAJAAAAAJ&hl=en">Raj Palleti</a>,
        <strong>Nidhya Shivakumar</strong>,
        <a href="https://cs.stanford.edu/~pliang/">Percy Liang</a>,
        <a href="https://dorsa.fyi/">Dorsa Sadigh</a>
        <br>
        <em>Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction</em>, 2023
        <br>
        <a href="https://arxiv.org/abs/2301.02555">arXiv</a>
        <p></p>
        <p>
		LILAC: a framework for incorporating natural language corrections online during execution, enabling robots to adapt to user feedback in real-time through shared autonomy with only a handful of demonstrations.
        </p>
      </td>
    </tr>

    <tr onmouseout="ever_stop()" onmouseover="ever_start()">
      <td style="padding:16px;width:20%;vertical-align:top">
        <div class="one">
          <div class="two" id='ever_image'>
					  <img src='images/drone_paper.png' width=100%>
                                    </div>
          <img src='images/drone_paper.png' width=100%>
                                </div>
        <script type="text/javascript">
          function ever_start() {
            document.getElementById('ever_image').style.opacity = "1";
          }

          function ever_stop() {
            document.getElementById('ever_image').style.opacity = "0";
          }
          ever_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:top">
        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10093000&tag=1">
			<span class="papertitle">Analysis of Aerial Images Using Deep Learning to Identify Critical Areas in Natural Disasters
</span>
        </a>
        <br>
				<strong>Nidhya Shivakumar</strong>
				<br>
        <em>2022 2nd International Conference on Robotics, Automation and Artificial Intelligence</em>, 2022
        <br>
        <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10093000&tag=1">IEEE Xplore</a>
        <p></p>
        <p>
				Automated disaster assessment using Faster R-CNN and Mask R-CNN on UAV imagery to identify damaged buildings and critical areas with 90% precision, reducing response times for search and rescue operations.
        </p>
      </td>
    </tr>

          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  <a href="https://github.com/jonbarron/jonbarron.github.io">Link to Template</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
    <script>
      // Route hash fragments to /cs180/ for backward compatibility
      // This ensures https://nidhya-s.github.io/#project0 still works
      (function() {
        const hash = window.location.hash;
        if (hash && hash.startsWith('#project')) {
          // Use relative path for local testing, absolute path for GitHub Pages
          const isLocal = window.location.protocol === 'file:';
          const basePath = isLocal ? 'cs180/index.html' : '/cs180/index.html';
          window.location.replace(basePath + hash);
        }
      })();
    </script>
</body>
</html>
